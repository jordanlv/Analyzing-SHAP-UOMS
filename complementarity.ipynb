{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5c4dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    compute_shap_similarity_pearson,\n",
    "    compute_ndcg_similarity,\n",
    "    compute_pred_jaccard,\n",
    "    compute_auc_roc,\n",
    "    compute_score_correlations,\n",
    "    load_nested_results,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4190b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = load_nested_results(\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "344c5b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21_Lymphography - 0.9964285714285716\n",
      "38_thyroid - 0.9526445655921953\n",
      "39_vertebral - 0.4117186302070023\n",
      "42_WBC - 0.98656330749354\n",
      "44_Wilt - 0.4107742873751187\n",
      "47_yeast - 0.41243399747230003\n",
      "4_breastw - 0.9687693877915169\n"
     ]
    }
   ],
   "source": [
    "datasets_to_del = []\n",
    "\n",
    "for name, results in all_results.items():\n",
    "    auc_roc, _ = compute_auc_roc(results)\n",
    "\n",
    "    median_auc_roc = np.median(auc_roc)\n",
    "    if median_auc_roc < 0.55 or median_auc_roc > 0.95:\n",
    "        datasets_to_del.append(name)\n",
    "        print(f\"{name} - {median_auc_roc}\")\n",
    "\n",
    "for d in datasets_to_del:\n",
    "    del all_results[d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11a605a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = list(all_results.keys())\n",
    "models_names = sorted(list(all_results[dataset_names[0]].keys() - {\"ground_truth\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b21a0d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14_glass\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_true_folds)):\n\u001b[32m     45\u001b[39m     y_true = y_true_folds[fold]\n\u001b[32m     47\u001b[39m     metric.append(\n\u001b[32m     48\u001b[39m         aggreg_f1_relative(\n\u001b[32m     49\u001b[39m             y_true,\n\u001b[32m     50\u001b[39m             np.array(\n\u001b[32m     51\u001b[39m                 [\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m                     all_results[dataset][\u001b[43mmodels_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m][fold][\u001b[33m\"\u001b[39m\u001b[33mpredictions\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     53\u001b[39m                     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m comb\n\u001b[32m     54\u001b[39m                 ]\n\u001b[32m     55\u001b[39m             ),\n\u001b[32m     56\u001b[39m         )\n\u001b[32m     57\u001b[39m     )\n\u001b[32m     59\u001b[39m dists_shap = []\n\u001b[32m     60\u001b[39m dists_ndcg = []\n",
      "\u001b[31mTypeError\u001b[39m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "\n",
    "def aggreg_f1_relative(y_true, y_preds):\n",
    "    best_score = np.median(\n",
    "        np.array([f1_score(y_true, y_preds[i]) for i in range(y_preds.shape[0])])\n",
    "    )\n",
    "    auc = f1_score(y_true, np.sum(y_preds, axis=0) >= 1)\n",
    "    return auc - best_score\n",
    "\n",
    "\n",
    "def aggreg_rank(y_true, y_preds):\n",
    "    ranks = [rankdata(scores, \"average\") for scores in y_preds]\n",
    "    mean_ranks = np.mean(ranks, axis=0)\n",
    "    return roc_auc_score(y_true, mean_ranks)\n",
    "\n",
    "\n",
    "scores = defaultdict(lambda: defaultdict(list))\n",
    "n_models_ensemblist = 3\n",
    "\n",
    "for dataset in dataset_names:\n",
    "    y_true_folds = all_results[dataset][\"ground_truth\"]\n",
    "\n",
    "    # Compute similarities on the full set of models first\n",
    "    shap_sim, _ = compute_shap_similarity_pearson(all_results[dataset])\n",
    "    ndcg_sim, _ = compute_ndcg_similarity(all_results[dataset])\n",
    "    scores_sim, _ = compute_score_correlations(all_results[dataset])\n",
    "    jaccard_sim, _ = compute_pred_jaccard(all_results[dataset])\n",
    "\n",
    "    print(dataset)\n",
    "\n",
    "    dist_shap_sim = 1 - np.array(shap_sim)\n",
    "    dist_ndcg_sim = 1 - np.array(ndcg_sim)\n",
    "    dist_scores_sim = 1 - np.array(scores_sim)\n",
    "    dist_jaccard_sim = 1 - np.array(jaccard_sim)\n",
    "\n",
    "    for comb in combinations(models_names, n_models_ensemblist):\n",
    "        metric = []\n",
    "\n",
    "        for fold in range(len(y_true_folds)):\n",
    "            y_true = y_true_folds[fold]\n",
    "\n",
    "            metric.append(\n",
    "                aggreg_f1_relative(\n",
    "                    y_true,\n",
    "                    np.array(\n",
    "                        [\n",
    "                            all_results[dataset][models_names[i]][fold][\"predictions\"]\n",
    "                            for i in comb\n",
    "                        ]\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        dists_shap = []\n",
    "        dists_ndcg = []\n",
    "        dists_scores = []\n",
    "        dists_jaccard = []\n",
    "\n",
    "        # Metric aggregation\n",
    "        for i in range(n_models_ensemblist):\n",
    "            for j in range(i + 1, n_models_ensemblist):\n",
    "                dists_shap.append(dist_shap_sim[comb[i], comb[j]])\n",
    "                dists_ndcg.append(dist_ndcg_sim[comb[i], comb[j]])\n",
    "                dists_scores.append(dist_scores_sim[comb[i], comb[j]])\n",
    "                dists_jaccard.append(dist_jaccard_sim[comb[i], comb[j]])\n",
    "\n",
    "        scores[dataset][\"name\"].append(f\"{'-'.join([models_names[i] for i in comb])}\")\n",
    "        scores[dataset][\"mcc\"].append(np.nanmean(metric))\n",
    "        scores[dataset][\"ndcg\"].append(np.mean(dists_ndcg))\n",
    "        scores[dataset][\"shap\"].append(np.mean(dists_shap))\n",
    "        scores[dataset][\"scores\"].append(np.mean(dists_scores))\n",
    "        scores[dataset][\"jaccard\"].append(np.mean(dists_jaccard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9a2f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "data = []\n",
    "\n",
    "for dataset in dataset_names:\n",
    "    mcc = scores[dataset][\"mcc\"]\n",
    "    r, _ = pearsonr(mcc, scores[dataset][\"shap\"])\n",
    "    r_w, _ = pearsonr(mcc, scores[dataset][\"ndcg\"])\n",
    "    r_s, _ = pearsonr(mcc, scores[dataset][\"scores\"])\n",
    "    r_J, _ = pearsonr(mcc, scores[dataset][\"jaccard\"])\n",
    "\n",
    "    data.append(\n",
    "        {\"Dataset\": dataset, \"shap\": r, \"NDCG\": r_w, \"Scores\": r_s, \"Jaccard\": r_J}\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(data).set_index(\"Dataset\")\n",
    "\n",
    "# Affichage propre\n",
    "print(df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eda7e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean().round(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shapspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
